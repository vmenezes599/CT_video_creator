{
    "1": {
        "inputs": {
            "unet_name": "wan22I2VA14BGGUF_a14bHigh.gguf"
        },
        "class_type": "UnetLoaderGGUF",
        "_meta": {
            "title": "Unet Loader (GGUF)"
        }
    },
    "2": {
        "inputs": {
            "unet_name": "wan22I2VA14BGGUF_a14bLow.gguf"
        },
        "class_type": "UnetLoaderGGUF",
        "_meta": {
            "title": "Unet Loader (GGUF)"
        }
    },
    "3": {
        "inputs": {
            "lora_name": "Wan2.2-Lightning_I2V-A14B-4steps-lora_HIGH_fp16.safetensors",
            "strength_model": 1,
            "model": [
                "1",
                0
            ]
        },
        "class_type": "LoraLoaderModelOnly",
        "_meta": {
            "title": "LoraLoaderModelOnly"
        }
    },
    "4": {
        "inputs": {
            "lora_name": "Wan2.2-Lightning_I2V-A14B-4steps-lora_LOW_fp16.safetensors",
            "strength_model": 1,
            "model": [
                "2",
                0
            ]
        },
        "class_type": "LoraLoaderModelOnly",
        "_meta": {
            "title": "LoraLoaderModelOnly"
        }
    },
    "5": {
        "inputs": {
            "shift": 5,
            "model": [
                "3",
                0
            ]
        },
        "class_type": "ModelSamplingSD3",
        "_meta": {
            "title": "ModelSamplingSD3"
        }
    },
    "6": {
        "inputs": {
            "shift": 5,
            "model": [
                "4",
                0
            ]
        },
        "class_type": "ModelSamplingSD3",
        "_meta": {
            "title": "ModelSamplingSD3"
        }
    },
    "7": {
        "inputs": {
            "add_noise": "enable",
            "noise_seed": 12345,
            "steps": 4,
            "cfg": 1,
            "sampler_name": "uni_pc",
            "scheduler": "normal",
            "start_at_step": 0,
            "end_at_step": 2,
            "return_with_leftover_noise": "enable",
            "model": [
                "5",
                0
            ],
            "positive": [
                "11",
                0
            ],
            "negative": [
                "11",
                1
            ],
            "latent_image": [
                "11",
                2
            ]
        },
        "class_type": "KSamplerAdvanced",
        "_meta": {
            "title": "KSampler (Advanced)"
        }
    },
    "8": {
        "inputs": {
            "add_noise": "disable",
            "noise_seed": 0,
            "steps": 4,
            "cfg": 1,
            "sampler_name": "uni_pc",
            "scheduler": "normal",
            "start_at_step": 2,
            "end_at_step": 4,
            "return_with_leftover_noise": "disable",
            "model": [
                "6",
                0
            ],
            "positive": [
                "11",
                0
            ],
            "negative": [
                "11",
                1
            ],
            "latent_image": [
                "7",
                0
            ]
        },
        "class_type": "KSamplerAdvanced",
        "_meta": {
            "title": "KSampler (Advanced)"
        }
    },
    "9": {
        "inputs": {
            "samples": [
                "8",
                0
            ],
            "vae": [
                "10",
                0
            ]
        },
        "class_type": "VAEDecode",
        "_meta": {
            "title": "VAE Decode"
        }
    },
    "10": {
        "inputs": {
            "vae_name": "wan_2.1_vae.safetensors"
        },
        "class_type": "VAELoader",
        "_meta": {
            "title": "Load VAE"
        }
    },
    "11": {
        "inputs": {
            "width": [
                "15",
                1
            ],
            "height": [
                "15",
                2
            ],
            "length": 61,
            "batch_size": 1,
            "positive": [
                "12",
                0
            ],
            "negative": [
                "13",
                0
            ],
            "vae": [
                "10",
                0
            ],
            "start_image": [
                "15",
                0
            ]
        },
        "class_type": "WanImageToVideo",
        "_meta": {
            "title": "WanImageToVideo"
        }
    },
    "12": {
        "inputs": {
            "text": "A close-up portrait of a woman with light skin and blue eyes, smiling at the camera. she appears to be in her mid-twenties, with long brown hair tied back in a ponytail, and is wearing a black and white leopard print blouse with a gold necklace. the woman is sitting in the middle of the frame, with her upper body visible, and she is looking directly at the viewer with a warm, inviting expression. her eyes are a bright blue color, and her hair is styled in loose waves. she is wearing gold earrings and has a mole on her left cheek. the background shows a dimly lit room with a wooden fence and a table and chairs, and the lighting is soft and warm, creating a cozy atmosphere.",
            "clip": [
                "21",
                0
            ]
        },
        "class_type": "CLIPTextEncode",
        "_meta": {
            "title": "CLIP Text Encode (Positive Prompt)"
        }
    },
    "13": {
        "inputs": {
            "text": "è‰²è°ƒè‰³ä¸½ï¼Œè¿‡æ›ï¼Œé™æ€ï¼Œç»†èŠ‚æ¨¡ç³Šä¸æ¸…ï¼Œå­—å¹•ï¼Œé£æ ¼ï¼Œä½œå“ï¼Œç”»ä½œï¼Œç”»é¢ï¼Œé™æ­¢ï¼Œæ•´ä½“å‘ç°ï¼Œæœ€å·®è´¨é‡ï¼Œä½è´¨é‡ï¼ŒJPEGå‹ç¼©æ®‹ç•™ï¼Œä¸‘é™‹çš„ï¼Œæ®‹ç¼ºçš„ï¼Œå¤šä½™çš„æ‰‹æŒ‡ï¼Œç”»å¾—ä¸å¥½çš„æ‰‹éƒ¨ï¼Œç”»å¾—ä¸å¥½çš„è„¸éƒ¨ï¼Œç•¸å½¢çš„ï¼Œæ¯å®¹çš„ï¼Œå½¢æ€ç•¸å½¢çš„è‚¢ä½“ï¼Œæ‰‹æŒ‡èåˆï¼Œé™æ­¢ä¸åŠ¨çš„ç”»é¢ï¼Œæ‚ä¹±çš„èƒŒæ™¯ï¼Œä¸‰æ¡è…¿ï¼ŒèƒŒæ™¯äººå¾ˆå¤šï¼Œå€’ç€èµ°",
            "clip": [
                "21",
                0
            ]
        },
        "class_type": "CLIPTextEncode",
        "_meta": {
            "title": "CLIP Text Encode (Negative Prompt)"
        }
    },
    "14": {
        "inputs": {
            "image": "chapter_001_image_005_00001_.png"
        },
        "class_type": "LoadImage",
        "_meta": {
            "title": "Load Image"
        }
    },
    "15": {
        "inputs": {
            "width": 832,
            "height": 480,
            "upscale_method": "nearest-exact",
            "keep_proportion": "crop",
            "pad_color": "0, 0, 0",
            "crop_position": "center",
            "divisible_by": 1,
            "device": "cpu",
            "image": [
                "14",
                0
            ]
        },
        "class_type": "ImageResizeKJv2",
        "_meta": {
            "title": "Resize Image v2"
        }
    },
    "17": {
        "inputs": {
            "model_name": "RealESRGAN_x4plus.pth"
        },
        "class_type": "UpscaleModelLoader",
        "_meta": {
            "title": "Load Upscale Model"
        }
    },
    "20": {
        "inputs": {
            "frame_rate": 12,
            "loop_count": 0,
            "filename_prefix": "WanI2VOutput",
            "format": "video/h264-mp4",
            "pix_fmt": "yuv420p",
            "crf": 19,
            "save_metadata": true,
            "trim_to_audio": false,
            "pingpong": false,
            "save_output": true,
            "images": [
                "27",
                0
            ]
        },
        "class_type": "VHS_VideoCombine",
        "_meta": {
            "title": "Video Combine ğŸ¥ğŸ…¥ğŸ…—ğŸ…¢"
        }
    },
    "21": {
        "inputs": {
            "clip_name": "umt5_xxl_fp8_e4m3fn_scaled.safetensors",
            "type": "wan",
            "device": "default"
        },
        "class_type": "CLIPLoader",
        "_meta": {
            "title": "Load CLIP"
        }
    },
    "26": {
        "inputs": {
            "images": [
                "15",
                0
            ]
        },
        "class_type": "PreviewImage",
        "_meta": {
            "title": "Preview Image"
        }
    },
    "27": {
        "inputs": {
            "color_space": "LAB",
            "factor": 1,
            "device": "gpu",
            "batch_size": 0,
            "image": [
                "9",
                0
            ],
            "reference": [
                "15",
                0
            ]
        },
        "class_type": "ImageColorMatch+",
        "_meta": {
            "title": "ğŸ”§ Image Color Match"
        }
    }
}